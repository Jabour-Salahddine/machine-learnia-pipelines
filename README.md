# Projet : API de Recommandation de Films

Ce projet a pour objectif de construire et de dÃ©ployer un systÃ¨me de recommandation de films basÃ© sur le filtrage collaboratif. L'API, construite avec FastAPI, fournit des recommandations personnalisÃ©es pour les utilisateurs connus et des recommandations populaires pour les nouveaux utilisateurs.

Ce fichier dÃ©crit comment le travail a Ã©tÃ© lancÃ©. L'objectif initial Ã©tait de rÃ©aliser simplement une API en local, Ã©tape par Ã©tape, jusqu'Ã  parvenir Ã  un pipeline reproductible et bien structurÃ©.

## Table des MatiÃ¨res
1. [FonctionnalitÃ©s](#1-fonctionnalitÃ©s)
2. [Architecture de l'Application](#2-architecture-de-lapplication)
3. [Installation et Lancement Local](#3-installation-et-lancement-local)
4. [DÃ©ploiement avec Docker](#4-dÃ©ploiement-avec-docker)
5. [DÃ©fis RencontrÃ©s et Solutions](#5-dÃ©fis-rencontrÃ©s-et-solutions)
6. [Vision d'un Projet Professionnel](#6-vision-dun-projet-professionnel)

---

## 1. FonctionnalitÃ©s

*   **Recommandations PersonnalisÃ©es :** Utilise un modÃ¨le SVD (Factorisation de Matrices) entraÃ®nÃ© sur le dataset MovieLens pour prÃ©dire les notes des films et recommander les plus pertinents pour un utilisateur donnÃ©.

*   **Gestion du "Cold Start" :** Pour les utilisateurs inconnus (qui n'Ã©taient pas dans l'ensemble d'entraÃ®nement), l'API retourne une liste des films les plus populaires, calculÃ©e en fonction du nombre de notes et de la note moyenne.

*   **API Robuste :** Construite avec FastAPI, offrant une documentation automatique (via Swagger UI) et une validation des types de donnÃ©es.


---

## 2. Architecture 1ere de l'Application

Le projet est structurÃ© pour sÃ©parer le code de l'application, les modÃ¨les et les donnÃ©es :

/recommendation-api/
|
â”œâ”€â”€ app/
| â””â”€â”€ main.py # Logique de l'API FastAPI
|
â”œâ”€â”€ models/
| â””â”€â”€ recommendation_model.pkl # ModÃ¨le SVD prÃ©-entraÃ®nÃ©
|
â”œâ”€â”€ data/
| â”œâ”€â”€ movies.csv # DonnÃ©es des films
| â””â”€â”€ ratings.csv # DonnÃ©es des notes
|
â”œâ”€â”€ .dockerignore # Fichiers Ã  ignorer par Docker, car on a rencontrer le problÃ¨me que l'image est trop grande
â”œâ”€â”€ Dockerfile # Recette pour construire l'image Docker
â””â”€â”€ requirements.txt # DÃ©pendances Python

---


## 3. Installation et Lancement Local

Il est fortement recommandÃ© d'utiliser un environnement virtuel isolÃ© pour Ã©viter les conflits de dÃ©pendances.

### 3.1. CrÃ©ation de l'environnement (avec Conda)

1.  **CrÃ©ez l'environnement :**

    ```bash
    conda create --name reco-api python=3.9 -y
    ```

2.  **Activez l'environnement :**
    
    ```bash
    conda activate reco-api
    ```

3.  **Installez les dÃ©pendances :** Le paquet `scikit-surprise` nÃ©cessite des outils de compilation. Il est prÃ©fÃ©rable de l'installer via `conda-forge` pour Ã©viter les erreurs de compilation sur Windows.
    
    ```bash
    conda install -c conda-forge scikit-surprise -y
    pip install -r requirements.txt
    ```
    
    *(Assurez-vous que `scikit-surprise` n'est PAS listÃ© dans `requirements.txt` si vous utilisez cette mÃ©thode)*

### 3.2. Lancement du serveur

Une fois l'environnement activÃ© et les dÃ©pendances installÃ©es, lancez le serveur FastAPI : (L'API sera accessible Ã  l'adresse http://127.0.0.1:8000.)
```bash
uvicorn app.main:app --reload

## ğŸš€ DÃ©ploiement avec Docker

La containerisation via Docker permet de rendre l'application portable, reproductible et facilement dÃ©ployable sur le cloud.

### ğŸ”§ 1. Construire lâ€™image Docker

```bash
docker build -t reco-api-image .
```

### â–¶ï¸ 2. Lancer le conteneur

Cette commande monte les dossiers de donnÃ©es et de modÃ¨les comme volumes afin de garder une image Docker lÃ©gÃ¨re et de manipuler facilement les fichiers volumineux.

```bash
docker run --rm -p 8000:8000 -v ./data:/app/data -v ./models:/app/models reco-api-image
```

---

## âš ï¸ DÃ©fis rencontrÃ©s & solutions apportÃ©es

Ce projet a soulevÃ© plusieurs dÃ©fis typiques du passage dâ€™un modÃ¨le de Machine Learning vers un environnement de production. Voici un rÃ©sumÃ© des principaux problÃ¨mes et des solutions apportÃ©es :

### ğŸ› ï¸ 1. Compilation de `scikit-surprise` sur Windows

- **ProblÃ¨me** : Lâ€™installation Ã©chouait Ã  cause de l'absence d'un compilateur C.
- **Solution** : Utilisation dâ€™un environnement Conda et installation du paquet via le canal `conda-forge`, qui fournit une version prÃ©-compilÃ©e.

### ğŸ§± 2. Erreur de sÃ©rialisation JSON

- **ProblÃ¨me** : Lâ€™API retournait une erreur 500 (Internal Server Error) car FastAPI ne savait pas convertir les types `numpy.int64` en JSON.
- **Solution** : Conversion manuelle des types NumPy vers des types Python natifs (`int()`).

### ğŸ§  3. ProblÃ¨me de consommation mÃ©moire

- **ProblÃ¨me** : Le chargement complet du fichier `ratings.csv` (~700 Mo) dÃ©passait la mÃ©moire disponible dans Docker.
- **Solution** : Chargement optimisÃ© avec `pandas.read_csv(usecols=...)` pour ne lire que les colonnes nÃ©cessaires.

### ğŸ³ 4. Taille de l'image Docker trop grande

- **ProblÃ¨me** : Inclusion des dossiers `/data` et `/models` dans lâ€™image, la rendant > 2.8 Go.
- **Solution** :
  - CrÃ©ation dâ€™un fichier `.dockerignore` pour exclure ces rÃ©pertoires.
  - Utilisation de volumes Docker pour les monter Ã  lâ€™exÃ©cution.

---

## ğŸŒ Vision dâ€™un dÃ©ploiement professionnel

Pour faire Ã©voluer ce prototype vers un systÃ¨me de production robuste, les Ã©tapes suivantes sont recommandÃ©es :

### ğŸ—ƒï¸ 1. Remplacement des fichiers CSV par une base de donnÃ©es

Utiliser une base managÃ©e (ex. : **Azure Database for PostgreSQL**) comme source de vÃ©ritÃ© pour les films et les notations. Lâ€™API interrogerait cette base plutÃ´t que de lire des fichiers locaux, ce qui la rendrait plus performante et scalable.

### ğŸ§± 2. Mise en place dâ€™un pipeline MLOps structurÃ©
Pour garantir la reproductibilitÃ©, la traÃ§abilitÃ© et la robustesse du cycle de vie des modÃ¨les, nous avons conÃ§u et implÃ©mentÃ© un pipeline de machine learning modulaire en utilisant :

ğŸ§ª ZenML comme orchestrateur principal,

ğŸ“Š MLflow pour le suivi des expÃ©riences (params, mÃ©triques, artefacts),

ğŸ³ Docker pour la conteneurisation,

ğŸ—„ï¸ MySQL pour stocker les donnÃ©es ainsi que les mÃ©tadonnÃ©es MLflow,

ğŸ§¼ Jupyter/Colab au dÃ©but pour les explorations et nettoyages manuels, puis migrÃ© vers des scripts standardisÃ©s.

Le pipeline se compose de plusieurs Ã©tapes bien distinctes :

ingest_data : chargement structurÃ© depuis MySQL,

train_model : entraÃ®nement dâ€™un modÃ¨le de type SVD (bibliothÃ¨que surprise),

evaluate_model : Ã©valuation du modÃ¨le loguÃ© dans MLflow avec une logique spÃ©cifique pour contourner lâ€™incompatibilitÃ© native entre surprise et les saveurs MLflow standards.


#### ğŸ§  Adaptation du modÃ¨le surprise.SVD Ã  MLflow
Ã‰tant donnÃ© que le modÃ¨le SVD de surprise nâ€™est pas compatible avec les formats standard supportÃ©s par MLflow (sklearn, keras, etc.), nous avons adoptÃ© une stratÃ©gie alternative :

Sauvegarde manuelle du modÃ¨le avec joblib,

Log de ce fichier comme artifact brut dans MLflow,

RÃ©cupÃ©ration et chargement explicite dans les Ã©tapes avales via mlflow.artifacts.download_artifacts().


#### ğŸš¦ RÃ©sultat : un pipeline reproductible, traÃ§able et prÃªt Ã  dÃ©ployer
GrÃ¢ce Ã  cette architecture :

Chaque exÃ©cution du pipeline est versionnÃ©e et suivie via MLflow,

Lâ€™ensemble du processus peut Ãªtre rejouÃ© et auditÃ© facilement,

Le modÃ¨le peut Ãªtre dÃ©ployÃ© ultÃ©rieurement via MLflow Deployer, ou packagÃ© pour une API de prÃ©diction en ligne (ex : FastAPI).
